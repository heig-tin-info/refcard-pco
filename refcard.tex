\documentclass{article}

\usepackage[a4paper, landscape, margin=1cm]{geometry}
\usepackage{fontspec}
\usepackage[french]{babel}
\usepackage[fontsize=6.5pt]{scrextend}
\usepackage[T1]{fontenc}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage{sectsty}
\usepackage{lmodern}
\usepackage{stix}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage{multirow}
\usepackage{titlesec}
\usepackage{graphicx}

\input{revision}

\ifdefined\tinted
  \pagecolor{Orchid!30}
\fi

\setlength{\parskip}{0.2em}
\setlength{\parindent}{0em}

% Highlight configuration for C programming language
\lstset{
  language=c++,
  breaklines=true,
  keywordstyle=\bfseries\color{black},
  basicstyle=\ttfamily\color{black},
  emphstyle={\em \color{gray}},
  emph={expr, type, NAME, ptr, name, expr, value, filename, label, member, type},
  mathescape=true,
  keepspaces=true,
  showspaces=false,
  showtabs=true,
  tabsize=3,
  columns=fullflexible,
  escapeinside={(*}{*)}
}

% Configuration
\renewcommand{\familydefault}{\sfdefault}

\sectionfont{\fontsize{12}{15}\selectfont}
\subsectionfont{\fontsize{10}{12}\selectfont}

\allsectionsfont{\sffamily\underline}

% No pages numbering
\pagenumbering{gobble}

% Titles and paragraphs more compact
\titlespacing*{\section}{0pt}{0pt}{0pt}
\titlespacing*{\subsection}{0pt}{0pt}{0pt}

\newlength\mybaselinestretch
\mybaselinestretch=0pt plus 0.02pt\relax
\addtolength{\baselineskip}{\mybaselinestretch}

\setlength\parindent{0pt}
\setlength\tabcolsep{1.5pt}
\setlength{\columnseprule}{0.4pt}

% Macros
\newcommand{\tab}{\hspace{2em}}
\newcommand{\etc}{\small \ldots}
\newcommand{\any}{$\hzigzag$~}
\newcommand{\spc}{$\mathvisiblespace$}
\newcommand{\cd}{\lstinline}

\begin{document}

\begin{multicols*}{3}

    \begin{tabularx}{\columnwidth}{lX}
        \raisebox{-\totalheight}{\includegraphics[width=1cm]{assets/heig-vd-black.pdf}} &
        \begin{center}
            {\Large \bf Carte de référence C++ (concurrence)} \\
            version \revision \ -- \revisiondate \\
        \end{center}
    \end{tabularx}

    Cette carte de référence peut être utilisée durant les travaux écrits et examens
    des cours \emph{progoo} et \emph{progoox} à moins que le contraire soit explicitement formulé.
    Elle est une liste non exhaustive des fonctionnalités de programmation concurrente en C++.
    Ci-dessous, la signification des termes utilisés dans cette carte de référence.

    \begin{tabularx}{\linewidth}{
            >{\hsize=0.5\hsize}X% 10% of 4\hsize
            >{\hsize=1.5\hsize}X% 30% of 4\hsize
            >{\hsize=0.5\hsize}X% 30% of 4\hsize
            >{\hsize=1.5\hsize}X% 30% of 4\hsize
            % sum=4.0\hsize for 4 columns
        }

        \tt \etc      & Continuation logique      & \tt \any  & N'importe quoi d'accepté     \\
        \tt /\any/    & Expression régulière      & \tt \spc  & Espace obligatoire           \\
        \cd{type}     & \tt int, long, float, ... & \cd{name} & \tt /[A-Za-z][A-Za-z0-9\_]+/ \\
        \cd{value}    & Valeur                    & \cd{NAME} & \tt /[A-Z][A-Z0-9\_]+/       \\
        \cd{filename} & Chemin de fichier relatif & \cd{expr} & e.g. \tt a + b               \\
    \end{tabularx}
    \hrule

    \section*{Threads}
    \begin{lstlisting}
#include <thread>
void func(int a, int b);         // Fonction à exécuter
std::thread t(func, 1, 2);       // Créer un thread
t.joinable();                    // Vérifier si le thread est actif
t.get_id();                      // Obtenir l'identifiant du thread
t.join();                        // Attendre la fin du thread
t.detach();                      // Détacher le thread de l'objet

std::this_thread::sleep_for(1s); // Attendre 1 seconde
std::this_thread::yield();       // Relâcher le CPU
std::thread::hardware_concurrency(); // Nombre de threads supportés par le CPU

auto std::thread t([]() {             // Lambda function
    std::cout << "Hello" << std::endl;
});

std::jthread jt([](std::stop_token st) { // Thread avec stop token
    while (!st.stop_requested()) {
        std::cout << "Hello" << std::endl;
    }
});
\end{lstlisting}

\section*{Verrous}
\begin{lstlisting}
#include <mutex>

std::mutex m;                     // Créer un mutex
m.lock();                         // Verrouiller le mutex
m.try_lock();                     // Essayer de verrouiller le mutex
m.unlock();                       // Déverrouiller le mutex

{
   std::lock_guard<std::mutex> lg(m); // Verrouillage automatique
   // Code critique
} // Déverrouillage automatique

{
    std::unique_lock<std::mutex> ul(m); // Verrouillage unique
    // Code critique
    ul.unlock();
    // Code non critique
    ul.lock();
} // Déverrouillage automatique


std::recursive_mutex rm;          // Mutex récursif
std::timed_mutex tm;              // Mutex avec temporisation
tm.try_lock_for(1s);              // Essayer de verrouiller pendant 1 seconde

std::recursive_timed_mutex rtm;   // Mutex récursif avec temporisation
\end{lstlisting}

\subsection*{Mutex récursif}
Un mutex récursif peut être verrouillé plusieurs fois par le même thread, mais doit être déverrouillé le même nombre de fois. Permet à un thread de verrouiller un mutex plusieurs fois sans se bloquer.

\begin{lstlisting}
static std::recursive_mutex rm;
void fibonacci(int n) {
    std::lock_guard<std::recursive_mutex> lg(rm);
    if (n <= 2) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);
}
\end{lstlisting}

\section*{Variables conditionnelles}

\begin{lstlisting}

#include <condition_variable>

std::condition_variable cv;       // Créer une variable conditionnelle

std::unique_lock<std::mutex> ul(m); // Vérrouillage
cv.wait(ul, []() { return condition; }); // Attendre une condition
// Mutex déverrouillé pendant l'attente, révérouillé après

cv.notify_one();                  // Réveiller un thread en attente
cv.notify_all();                  // Réveiller tous les threads en attente

\end{lstlisting}

\section*{Atomics}

\begin{lstlisting}
#include <atomic>

std::atomic<int> a;               // Créer une variable atomique
a.store(42);                      // Écrire une valeur
a.load();                         // Lire une valeur
\end{lstlisting}
\section*{Sémaphores}

\begin{lstlisting}
#include <semaphore> // C++20

std::counting_semaphore sem(2);   // Créer un sémaphore avec 2 jetons
sem.acquire();                    // Acquérir un jeton (décrémenter, bloquant)
sem.release();                    // Libérer un jeton (incrémenter)

std::binary_semaphore bsem;       // Créer un sémaphore binaire
bsem.acquire();                   // Acquérir le jeton (bloquant)
bsem.release();                   // Libérer le jeton

\end{lstlisting}

\section*{Barrières et latches}
\begin{lstlisting}
#include <barrier> // C++20

std::barrier b(2);                // Créer une barrière avec 2 threads
b.arrive_and_wait();              // Attendre que les 2 threads arrivent à la barrière

b.arrive_and_drop();              // Attendre que tous les threads arrivent et libérer la barrière

#include <latch> // C++20

std::latch l(2);                   // Créer une latch pour deux threads

l.count_down();                   // Décrémenter la latch
l.wait();                         // Attendre que la latch atteigne zéro
\end{lstlisting}

\section*{Futures et Promesses}

\begin{lstlisting}
#include <future>

std::promise<int> p;              // Créer une promesse
std::future<int> f = p.get_future(); // Obtenir le futur associé à la promesse
p.set_value(42);                  // Mettre une valeur dans la promesse, débloquer le futur
f.get();                          // Attendre la valeur de la promesse
\end{lstlisting}

\section*{Ordre de mémoire}

\begin{lstlisting}
#include <atomic>

std::atomic_thread_fence(std::memory_order_acquire); // Barrière d'acquisition

std::atomic_thread_fence(std::memory_order_release); // Barrière de libération

std::memory_order_relaxed;       // Aucun ordre n'est garanti
std::memory_order_consume;       // Garantit la lecture des dépendances
std::memory_order_acquire;       // Garantit la lecture des données
std::memory_order_release;       // Garantit l'écriture des données
std::memory_order_acq_rel;       // Garantit la lecture et l'écriture des données
std::memory_order_seq_cst;       // Garantit l'ordre séquentiel
\end{lstlisting}

Dans cet exemple, le compilateur peut décider de réordonner les instructions de manière à ce que \cd{y} soit affecté avant \cd{b}, car il n'y a pas de dépendance entre les deux instructions, et le compilateur ne sait pas que \cd{t1} et \cd{t2} sont exécutés en parallèle.

\begin{lstlisting}
int a = 0, b = 0;
int x = 0, y = 0;
void t1() { a = 1; x = b; }
void t2() { b = 1; y = a; }
\end{lstlisting}

En utilisant des ordres de mémoire, on peut garantir que les instructions sont exécutées dans l'ordre spécifié.

\begin{lstlisting}
std::atomic<int> a = 0, b = 0;
std::atomic<int> x = 0, y = 0;

void thread1() {
    // Libération : toutes les écritures avant cette ligne sont visibles
    a.store(1, std::memory_order_release);
    // Acquisition : toutes les lectures après cette ligne voient les écritures précédentes
    x = b.load(std::memory_order_acquire);
}

void thread2() {
    // Libération : toutes les écritures avant cette ligne sont visibles
    b.store(1, std::memory_order_release);
    // Acquisition : toutes les lectures après cette ligne voient les écritures précédentes
    y = a.load(std::memory_order_acquire);
}
\end{lstlisting}

\section*{Gestion d'arrêt}
\begin{lstlisting}
#include <stop_token> // C++20

std::stop_source ss;
std::stop_token st = ss.get_token();

while (!st.stop_requested()) {
    // Code
}

ss.request_stop(); // Demander l'arrêt

// Utile avec std::jthread
std::jthread jt([](std::stop_token st) {
    while (!st.stop_requested()) {
        // Code
    }
});

jt.request_stop(); // Demander l'arrêt
\end{lstlisting}

\section*{Asynchronisme}

\begin{lstlisting}
#include <future>

// Exécuter de manière asynchrone
std::future<int> f = std::async(std::launch::async, []() {
    return 42;
});
f.get(); // Attendre le résultat

// Exécuter de manière différée
std::future<int> f = std::async(std::launch::deferred, []() {
    return 42;
});
f.get(); // Déclencher l'exécution et attendre le résultat
\end{lstlisting}

\section*{OpenMP}

\begin{lstlisting}
#include <omp.h>

#pragma omp parallel
{
    // Code exécuté par chaque thread
}

#pragma omp parallel for
for (int i = 0; i < 10; ++i) {
    // Code exécuté par chaque thread
}

int sum = 0;
#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < 10; ++i) {
    sum += i;
}

\end{lstlisting}

\section*{Moniteur}

\begin{lstlisting}
#include <condition_variable>

class Monitor {
public:
    void enter() {
        std::unique_lock<std::mutex> lock(m);
        cv.wait(lock, [this] { return !locked; });
        locked = true;
    }

    void leave() {
        std::lock_guard<std::mutex> lock(m);
        locked = false;
        cv.notify_one();
    }

private:
    std::mutex m;
    std::condition_variable cv;
    bool locked = false;
};
\end{lstlisting}

\section*{Gestion du temps}

\begin{lstlisting}
#include <chrono>

std::chrono::system_clock::time_point now = std::chrono::system_clock::now();
std::chrono::system_clock::time_point epoch; // Temps UNIX
std::this_thread::sleep_for(123ms);

// Constantes littérales temporelles C++14
auto u = 42us; // Microsecondes
\end{lstlisting}

Exemple de mesure du temps d'exécution d'une fonction.

\begin{lstlisting}
auto start = std::chrono::high_resolution_clock::now();
function();
auto end = std::chrono::high_resolution_clock::now();
auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
std::cout << duration.count() << "ms" << std::endl;
\end{lstlisting}

\section*{Alignement de la mémoire}

\begin{lstlisting}
#include <new>

void* p = operator new(42);       // Allouer de la mémoire alignée
operator delete(p);               // Libérer la mémoire

void* p = operator new(42, std::align_val_t(64)); // Allouer de la mémoire alignée sur 64 octets

struct alignas(64) S { int x; };  // Alignement de la structure

// Cette constante représente la taille en octets de la plus petite unité de mémoire qui peut être affectée par le false sharing.
std::hardware_destructive_interference_size;

// Cette constante représente la taille en octets de la plus grande unité de mémoire qui est avantageuse à partager entre les threads.
std::hardware_constructive_interference_size;
\end{lstlisting}

\section*{Tâche asynchrone générique}
Utilisation de \cd{std::packaged\_task} pour encapsuler une fonction et obtenir un futur associé.

\begin{lstlisting}
#include <future>

int add(int a, int b) { return a + b; }

std::packaged_task<int(int, int)> task(add);
std::future<int> f = task.get_future();
task(1, 2);

f.get(); // Attendre le résultat

// Avec bind et lambda
std::packaged_task<int()> task(std::bind(add, 1, 2));
std::future<int> f = task.get_future();
task();
f.get(); // Attendre le résultat

// Avec arguments génériques (templates)
template <typename F, typename... Args>
auto async(F&& f, Args&&... args) {
    std::packaged_task<std::invoke_result_t<F, Args...>()> task(std::bind(std::forward<F>(f), std::forward<Args>(args)...));
    std::future<std::invoke_result_t<F, Args...>()> f = task.get_future();
    task();
    return f;
}

auto f = async(add, 1, 2);

f.get(); // Attendre le résultat
\end{lstlisting}

\section*{Algorithmes parallèles (C++17)}

\begin{lstlisting}
#include <execution>

std::vector<int> vec(1000, 1);
std::for_each(std::execution::par, vec.begin(), vec.end(), [](int& n) {
    n *= 2; });
\end{lstlisting}

\section*{Coroutines (C++20)}

\begin{lstlisting}
    #include <coroutine>
    #include <iostream>

    struct ReturnObject {
        struct promise_type {
            ReturnObject get_return_object() { return {}; }
            std::suspend_never initial_suspend() { return {}; }
            std::suspend_never final_suspend() noexcept { return {}; }
            void return_void() {}
            void unhandled_exception() { std::terminate(); }
        };
    };

    ReturnObject foo() {
        std::cout << "Hello" << std::endl;
        co_await std::suspend_always{};
        std::cout << "World" << std::endl;
    }

    int main() {
        auto ret = foo();
        // Coroutine starts, prints "Hello", suspends, then resumes and prints "World"
    }
\end{lstlisting}

\section*{Processus}

\begin{lstlisting}
#include <unistd.h>

pid_t pid = fork();               // Créer un processus enfant
if (pid == 0) {
    // Code du processus enfant
    auto parent_pid = getppid();
} else if (pid == -1) {
    // Erreur
} else {
    // Code du processus parent
    auto child_pid = pid;
}
\end{lstlisting}

\section*{IPC}

\begin{lstlisting}
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>

// Mémoire partagée
key_t key = ftok("file", 42);     // Générer une clé unique
int shmid = shmget(key, 1024, 0666 | IPC_CREAT); // Créer un segment de mémoire partagée
void* addr = shmat(shmid, NULL, 0); // Attacher le segment de mémoire partagée
shmctl(shmid, IPC_RMID, NULL);     // Supprimer le segment de mémoire partagée

// Sémaphores
int semid = semget(key, 1, 0666 | IPC_CREAT); // Créer un ensemble de sémaphores
semctl(semid, 0, SETVAL, 1);      // Initialiser le sémaphore à 1
semop(semid, &op, 1);              // Opération sur le sémaphore

// Files de messages
int msqid = msgget(key, 0666 | IPC_CREAT); // Créer une file de messages
msgsnd(msqid, &msg, sizeof(msg), 0); // Envoyer un message
msgrcv(msqid, &msg, sizeof(msg), 0, 0); // Recevoir un message
msgctl(msqid, IPC_RMID, NULL);    // Supprimer la file de messages

// Signaux
kill(pid, SIGKILL);               // Envoyer un signal
signal(SIGINT, handler);          // Gérer un signal

// Pipes
int fd[2];
pipe(fd);                         // Créer un tube
write(fd[1], "Hello", 5);         // Écrire dans le tube
read(fd[0], buf, 5);              // Lire depuis le tube
close(fd[0]);                     // Fermer le tube
\end{lstlisting}

\end{multicols*}
\end{document}
